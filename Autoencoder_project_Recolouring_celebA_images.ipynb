{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "Autoencoder project - Recolouring celebA images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeerajGithubIITM/Autoencoder/blob/main/Autoencoder_project_Recolouring_celebA_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okTSGxhkNkGt",
        "outputId": "43d2a7d6-0e45-4ed4-a287-de3a08d41ed6"
      },
      "source": [
        "from google.colab import drive, files\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IRIY-hBwsw2"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Activation, Dense, Dropout, Flatten, BatchNormalization,Reshape, Input, ZeroPadding2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.image import  array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "\n",
        "\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
        "\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n4CPJ5BOA5e"
      },
      "source": [
        "zip_path = \"/content/drive/MyDrive/img_align_celeba.zip\"\n",
        "zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "dataset = os.listdir('/tmp/img_align_celeba')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lQJQEiOVEf_"
      },
      "source": [
        "images = []\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for img in dataset[2048:4096]:\n",
        "  # image = img_to_array(load_img('/tmp/img_align_celeba/' + img))\n",
        "  # images.append(image)\n",
        "\n",
        "  x = rgb2lab(1.0/255*img_to_array(load_img('/tmp/img_align_celeba/' + img)))[:,:,0]\n",
        "  X.append(x)\n",
        "\n",
        "  y = rgb2lab(1.0/255*img_to_array(load_img('/tmp/img_align_celeba/' + img)))[:,:,1:]\n",
        "  Y.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkM2tKyHrl3N"
      },
      "source": [
        "# for img in images:\n",
        "#   x = rgb2lab(1.0/255*img)[:,:,0]\n",
        "#   X.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnbyigA_bFMA"
      },
      "source": [
        "# for img in images:\n",
        "#   y = rgb2lab(1.0/255*img)[:,:,1:]\n",
        "#   Y.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXWycQmYhEBL"
      },
      "source": [
        "X_train = np.expand_dims(np.asarray(X), axis = -1)\n",
        "Y_train = np.asarray(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM1scLPJwsxE"
      },
      "source": [
        "# model = Sequential([\n",
        "#     Input(shape = (218,178,1)),\n",
        "#     Conv2D(8, kernel_size = (3,3), strides = (2,2), padding = 'same', activation = 'relu'),\n",
        "#     Conv2D(8, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu'),\n",
        "#     Conv2D(16, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu'),\n",
        "#     Conv2D(16, kernel_size = (3,3), strides = (2,2), padding = 'same', activation = 'relu'),\n",
        "#     Conv2D(32, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu'),\n",
        "#     Conv2D(32, kernel_size = (3,3), strides = (2,2), padding = 'same', activation = 'relu'),\n",
        "#     UpSampling2D(size=(2,2)),\n",
        "#     Conv2D(32, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu'),\n",
        "#     UpSampling2D(size=(2,2)),\n",
        "#     Conv2D(16, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu'),\n",
        "#     UpSampling2D(size=(2,2)),\n",
        "#     Conv2D(2, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu')\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mwn9gX3wsxE"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB0RkAjvwsxF"
      },
      "source": [
        "# model.compile(optimizer = Adam(lr = 0.001), loss = 'mse')\n",
        "# history = model.fit(X_train, Y_train, batch_size = 64, epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Ixx_Ll3fN_"
      },
      "source": [
        "# loss = history.history['loss']\n",
        "\n",
        "# epochs = range(len(loss))\n",
        "\n",
        "# plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "# plt.title('Training loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNdwRtZKkke6"
      },
      "source": [
        "# model.save('model2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqYe6YAt4vCX",
        "outputId": "3c392693-1d34-440c-9de1-f8655d79edb1"
      },
      "source": [
        "VGG_model = VGG19(include_top = False, input_shape = (218, 178, 3))\n",
        "# VGG_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5BFZ-3Q9nDz",
        "outputId": "efdb8987-a669-4706-9233-3e5573e2ef53"
      },
      "source": [
        "decoder_model = Sequential([Input(shape = (218,178,1)),\n",
        "                            Conv2D(3, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')])\n",
        "\n",
        "for layer in VGG_model.layers[1:15]: \n",
        "  decoder_model.add(layer)\n",
        "for layer in decoder_model.layers:\n",
        "  layer.trainable = False\n",
        "decoder_model.layers[0].trainable = True\n",
        "\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 218, 178, 3)       30        \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 218, 178, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 218, 178, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 109, 89, 64)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 109, 89, 128)      73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 109, 89, 128)      147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 54, 44, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 54, 44, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 54, 44, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 54, 44, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 54, 44, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 27, 22, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 27, 22, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 27, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 27, 22, 512)       2359808   \n",
            "=================================================================\n",
            "Total params: 8,225,374\n",
            "Trainable params: 30\n",
            "Non-trainable params: 8,225,344\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd9UP281IXH5",
        "outputId": "84cad893-2adc-499e-eadb-559f8bb2369d"
      },
      "source": [
        "encoder_model = decoder_model.output\n",
        "\n",
        "encoder_model = ZeroPadding2D(1)(encoder_model)\n",
        "encoder_model = Conv2D(512, kernel_size = (2,2), strides = (1,1), padding = 'valid', activation = 'relu')(encoder_model)\n",
        "encoder_model = Conv2D(512, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(encoder_model)\n",
        "encoder_model = BatchNormalization()(encoder_model)\n",
        "encoder_model = Conv2D(512, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(encoder_model)\n",
        "\n",
        "\n",
        "encoder_model = UpSampling2D(size=(2,2))(encoder_model)\n",
        "encoder_model = Conv2D(256, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(encoder_model)\n",
        "encoder_model = Conv2D(256, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(encoder_model)\n",
        "encoder_model = BatchNormalization()(encoder_model)\n",
        "encoder_model = Conv2D(256, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(encoder_model)\n",
        "\n",
        "\n",
        "encoder_model = UpSampling2D(size=(2,2))(encoder_model)\n",
        "encoder_model = Conv2D(128, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(encoder_model)\n",
        "encoder_model = BatchNormalization()(encoder_model)\n",
        "encoder_model = Conv2D(128, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(encoder_model)\n",
        "\n",
        "\n",
        "encoder_model = UpSampling2D(size=(2,2))(encoder_model)\n",
        "encoder_model = Conv2D(64, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu')(encoder_model)\n",
        "encoder_model = BatchNormalization()(encoder_model)\n",
        "encoder_model = Conv2D(64, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu')(encoder_model)\n",
        "\n",
        "\n",
        "encoder_model = Conv2D(2, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu')(encoder_model)\n",
        "\n",
        "\n",
        " \n",
        "auto_encoder = Model(inputs = decoder_model.input, outputs = encoder_model)    \n",
        "auto_encoder.summary()    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 218, 178, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 218, 178, 3)       30        \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 218, 178, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 218, 178, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 109, 89, 64)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 109, 89, 128)      73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 109, 89, 128)      147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 54, 44, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 54, 44, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 54, 44, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 54, 44, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 54, 44, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 27, 22, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 27, 22, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 27, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 27, 22, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 29, 24, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 23, 512)       1049088   \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 23, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 23, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 23, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 56, 46, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 46, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 46, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 56, 46, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 46, 256)       590080    \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 112, 92, 256)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 112, 92, 128)      295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 112, 92, 128)      512       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 112, 92, 128)      147584    \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 224, 184, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 222, 182, 64)      73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 222, 182, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 220, 180, 64)      36928     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 218, 178, 2)       1154      \n",
            "=================================================================\n",
            "Total params: 16,912,480\n",
            "Trainable params: 8,685,216\n",
            "Non-trainable params: 8,227,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlRLo80PNGws",
        "outputId": "869ca1a5-4b94-4e2b-c114-7c30336cafa0"
      },
      "source": [
        "auto_encoder.compile(optimizer = Adam(lr = 0.001), loss = 'mse')\n",
        "history2 = auto_encoder.fit(X_train, Y_train, batch_size = 128, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctiUKGCcNTBJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "20667e31-7ba1-48ab-9999-90a5c2b4f24c"
      },
      "source": [
        "loss = history2.history['loss']\n",
        "loss.pop(0)\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCloMvXOTGem"
      },
      "source": [
        "auto_encoder.save('auto_encoder4.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqoN7-CMgHDu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ea86d7ad-fffd-482b-e983-6558f1a00215"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('auto_encoder4.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fece509f-4689-4038-9c62-b20537f143ae\", \"auto_encoder4.h5\", 137334984)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62N8EDy1ilFU"
      },
      "source": [
        "def upload_and_predict(model):\n",
        "\n",
        "  uploaded=files.upload()\n",
        "\n",
        "  n = len(uploaded)\n",
        "  i = 1\n",
        "  plt.figure(figsize=(15, 5*n))\n",
        "\n",
        "  for fn in uploaded.keys():\n",
        " \n",
        "    path='/content/' + fn\n",
        "    img=load_img(path, target_size=(218, 178))\n",
        "  \n",
        "    x_star=img_to_array(img)\n",
        "    x = rgb2lab(1.0/255*x_star)[:,:,0]\n",
        "\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    pred = model.predict(np.expand_dims(x, axis = -1))\n",
        "    recon_image = np.concatenate((np.expand_dims(x, axis = -1), pred), axis = -1)\n",
        "\n",
        "    plt.subplot(n, 3, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.subplot(n, 3, i+1)\n",
        "    plt.imshow(x[0], cmap = 'gray')\n",
        "    plt.title('Grayscaled Image')\n",
        "\n",
        "    plt.subplot(n, 3, i+2)\n",
        "    plt.imshow(lab2rgb(recon_image[0]))\n",
        "    plt.title('Re-Coloured Image')\n",
        "\n",
        "    i+=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz4PF0qibAWC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}